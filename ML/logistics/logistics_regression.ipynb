{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 作业2-年收入判断\n",
    "\n",
    "## 项目描述\n",
    "二元分类是机器学习中最基础的问题之一，在这份教学中，你将学会如何实作一个线性二元分类器，来根据人们的个人资料，判断其年收入是否高于 50,000 美元。我们将以两种方法: logistic regression 与 generative model，来达成以上目的，你可以尝试了解、分析两者的设计理念及差别。\n",
    "实现二分类任务：\n",
    "* 个人收入是否超过50000元？\n",
    "\n",
    "## 数据集介绍\n",
    "这个资料集是由UCI Machine Learning Repository 的Census-Income (KDD) Data Set 经过一些处理而得来。为了方便训练，我们移除了一些不必要的资讯，并且稍微平衡了正负两种标记的比例。事实上在训练过程中，只有 X_train、Y_train 和 X_test 这三个经过处理的档案会被使用到，train.csv 和 test.csv 这两个原始资料档则可以提供你一些额外的资讯。\n",
    "* 已经去除不必要的属性。\n",
    "* 已经平衡正标和负标数据之间的比例。\n",
    "\n",
    "**特征格式**\n",
    "1. train.csv，test_no_label.csv。\n",
    "* 基于文本的原始数据\n",
    "* 去掉不必要的属性，平衡正负比例。\n",
    "2. X_train, Y_train, X_test(测试)\n",
    "* train.csv中的离散特征=>在X_train中onehot编码(学历、状态...)\n",
    "* train.csv中的连续特征 => 在X_train中保持不变(年龄、资本损失...)。\n",
    "* X_train, X_test : 每一行包含一个510-dim的特征，代表一个样本。\n",
    "* Y_train: label = 0 表示 \"<=50K\" 、 label = 1 表示 \" >50K \" 。\n",
    "\n",
    "## 项目要求\n",
    "1. 请动手编写 gradient descent 实现 logistic regression\n",
    "1. 请动手实现概率生成模型。\n",
    "1. 单个代码块运行时长应低于五分钟。\n",
    "1. 禁止使用任何开源的代码(例如，你在GitHub上找到的决策树的实现)。\n",
    "\n",
    "## 数据准备\n",
    "项目数据保存在：work/data/ 目录下。\n",
    "\n",
    "## 环境配置/安装\n",
    "无"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 下面该你动手啦！\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn import  metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv('work/data/X_train')\r\n",
    "X_test = pd.read_csv('work/data/X_test')\r\n",
    "Y_test = pd.read_csv('work/output_logistic.csv')\r\n",
    "Y_test = Y_test.iloc[:,1:].to_numpy()\r\n",
    "X_test = X_test.iloc[:,1:].to_numpy()\r\n",
    "X = X.iloc[:,1:].to_numpy()\r\n",
    "Y = pd.read_csv('work/data/Y_train')\r\n",
    "Y = Y.iloc[:,1:].to_numpy()\r\n",
    "MinMax = preprocessing.MinMaxScaler()\r\n",
    "x_scale = MinMax.fit_transform(X)\r\n",
    "data_x = x_scale\r\n",
    "data_y = Y\r\n",
    "test_x = MinMax.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### for SGD\r\n",
    "def sigmoid(x):\r\n",
    "    y = 1/(1+np.exp(x))\r\n",
    "    return y\r\n",
    "\r\n",
    "\r\n",
    "def mini_batch(batch_size, data_X, data_Y):\r\n",
    "    idx = np.arange(0, data_X.shape[0])\r\n",
    "    np.random.shuffle(idx)\r\n",
    "    idx = idx[0:batch_size]\r\n",
    "\r\n",
    "    return data_X[idx,:], data_Y[idx,:]\r\n",
    "\r\n",
    "class logistics_regression():\r\n",
    "\r\n",
    "    def __init__(self,X_train, label):\r\n",
    "        self.X = X_train\r\n",
    "        self.Y = label\r\n",
    "        self.weight1 = np.random.normal(0,0.5,[1,self.X.shape[1]])\r\n",
    "        self.b = np.random.normal(0,0.5,[1,1])\r\n",
    "        self.lr = 0.1\r\n",
    "        self.g_w = np.zeros(self.weight1.shape)\r\n",
    "        self.g_b = np.zeros(self.b.shape)\r\n",
    "        self.loss = 0\r\n",
    "        self.eps = 0.00001\r\n",
    "\r\n",
    "    def train(self):\r\n",
    "        m = self.X.shape[0]\r\n",
    "        # loss = 0\r\n",
    "\r\n",
    "\r\n",
    "        for i in range(m):\r\n",
    "            for j in range(5):\r\n",
    "                output = self.forward(self.X[i,:])\r\n",
    "                gw = (output - self.Y[i,:])*self.X[i,:]\r\n",
    "                self.g_w += gw**2\r\n",
    "                self.weight1 = self.weight1 + self.lr * gw/(np.sqrt(self.g_w)+self.eps)\r\n",
    "                # self.weight1 = self.weight1 + self.lr * gw\r\n",
    "                gb = (output - self.Y[i,:])\r\n",
    "                self.g_b += gb**2\r\n",
    "                self.b = self.b + self.lr * gb/(np.sqrt(self.g_b)+self.eps)\r\n",
    "                # self.b = self.b + self.lr * gb\r\n",
    "\r\n",
    "        for j in range(m):\r\n",
    "            self.loss += self.Y[j,:]*np.log(self.forward(self.X[j,:]) + self.eps) + (1 - self.Y[j,:])*np.log(1 - self.forward(self.X[j,:]) + self.eps)   \r\n",
    "        self.loss = -self.loss\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        y_pred = sigmoid(np.dot(self.weight1, x) + self.b)\r\n",
    "        # y_pred = np.dot(self.weight1, x) + np.dot(self.weight2, x**2) + self.b\r\n",
    "        return y_pred \r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2809.15164883]]\n"
     ]
    }
   ],
   "source": [
    "iter = 50\r\n",
    "batch_size = 10000\r\n",
    "\r\n",
    "# x = np.array([[0,0,0],[1,1,1]])\r\n",
    "# y = np.array([[0],[1]])\r\n",
    "# data_x = x\r\n",
    "# data_y = y\r\n",
    "\r\n",
    "x_batch, y_batch = mini_batch(batch_size, data_x,data_y)\r\n",
    "LG = logistics_regression(x_batch,y_batch)\r\n",
    "for epoch in range(iter):\r\n",
    "    x_batch, y_batch = mini_batch(batch_size, data_x,data_y)\r\n",
    "    LG.X = x_batch\r\n",
    "    LG.Y = y_batch\r\n",
    "    for i in range(10):\r\n",
    "        LG.loss = 0\r\n",
    "        LG.train()\r\n",
    "        if i % 100 == 0:\r\n",
    "            print(LG.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.2564197]]), array([0]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch, y_batch = mini_batch(1, data_x,data_y)\r\n",
    "LG = logistics_regression(x_batch,y_batch)\r\n",
    "LG.weight1 = np.load('weight.npy')\r\n",
    "LG.b = np.load('bias.npy')\r\n",
    "op = 1\r\n",
    "LG.forward(data_x[op,:]), data_y[op,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.84450424]]), array([1]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LG = logistics_regression(x_batch,y_batch)\r\n",
    "op = 27619\r\n",
    "LG.forward(test_x[op,:]), Y_test[op,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = LG.forward(test_x.T)\r\n",
    "result = scores.copy()\r\n",
    "result[np.where(scores >= 0.5)] = 1\r\n",
    "result[np.where(scores < 0.5)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9501122293823764\n",
      "auc: 0.9832468647415978\n"
     ]
    }
   ],
   "source": [
    "print('acc:', 1 - np.sum((result - Y_test.T)**2)/Y_test.shape[0])\r\n",
    "print('auc:', metrics.roc_auc_score(Y_test, scores.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       label\n",
      "0          0\n",
      "1          1\n",
      "2          0\n",
      "3          0\n",
      "4          0\n",
      "...      ...\n",
      "27617      0\n",
      "27618      0\n",
      "27619      1\n",
      "27620      0\n",
      "27621      0\n",
      "\n",
      "[27622 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "csv_result = pd.DataFrame(result.T)\r\n",
    "csv_result.columns = [\"label\"]\r\n",
    "csv_result[\"label\"] = csv_result[\"label\"].astype(int)\r\n",
    "# csv_result.index = ['id' + str(i) for i in range(result.shape[1])]\r\n",
    "print(csv_result)\r\n",
    "csv_result.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save(\"weight.npy\", LG.weight1)\r\n",
    "np.save(\"bias.npy\", LG.b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
