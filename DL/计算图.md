# 计算图

在深度学习框架里底层实现`Back-propagation`算法是通过构建计算图完成，普通的一元运算和二元运算可以简单地通过二叉树实现，

```python
class Node():
    def __init__(self):
        self.last_right = None
        self.last_left = None
        self.next = None
        self.value = None
        self.grad = None
        self.sub_grad = None
        self.require_grad = True
```

二叉树的一个节点的属性如上，我们可以通过继承上面这个基类去设计更多类型的节点，如变量节点`(Variable)`，常数节点`(Constant)`，操作符节点`(Operator)`，输入节点`Input`等等。

每个节点设计有如下方法：

```python
def output_val(self):
    pass

def compute_gradient(self):
    pass

def update_param(self):
    pass
```



### Dimension Analysis



### Dense层的设计

这里把全连接层直接设计为一个节点，这样可以减少整个二叉树的大小，遍历起来速度应该也会快些。

