{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2021/4/10 18:08\n",
    "# @Author  : Weiming Mai\n",
    "# @FileName: main.py\n",
    "# @Software: PyCharm\n",
    "\n",
    "import numpy as np\n",
    "from Nodes import *\n",
    "from Utils import *\n",
    "from numpy import *\n",
    "import xlrd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# read data\n",
    "def excel_to_matrix(path, num):\n",
    "    table = xlrd.open_workbook(path).sheets()[num]  # 获取第一个sheet表\n",
    "    row = table.nrows  # 行数\n",
    "    col = table.ncols  # 列数\n",
    "    datamatrix = np.zeros((row, col))  # 生成一个nrows行ncols列，且元素均为0的初始矩阵\n",
    "    for x in range(col):\n",
    "        cols = np.matrix(table.col_values(x))  # 把list转换为矩阵进行矩阵操作\n",
    "        datamatrix[:, x] = cols  # 按列把数据存进矩阵中\n",
    "        # 数据归一化\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        datamatrix = min_max_scaler.fit_transform(datamatrix)\n",
    "    return datamatrix\n",
    "\n",
    "def mini_batch(batch_size, data_X, data_Y):\n",
    "    idx = np.arange(0, data_X.shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[0:batch_size]\n",
    "\n",
    "    return data_X[idx,:], data_Y[idx,:]\n",
    "\n",
    "datafile = \"C:/Users/13271/Desktop/git/DL/iris_test+train.xlsx\"\n",
    "\n",
    "data_x = excel_to_matrix(datafile, 0)\n",
    "data_y = excel_to_matrix(datafile, 3)\n",
    "\n",
    "x_test = excel_to_matrix(datafile, 1)\n",
    "y_test = excel_to_matrix(datafile, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7498369511896593\n",
      "0.7522530589326535\n",
      "0.6718931771350132\n",
      "0.6479640472075985\n",
      "0.617834395617777\n",
      "0.5993706129449777\n",
      "0.397761203404795\n",
      "0.22787035841808448\n",
      "0.4233678238577885\n",
      "0.2895759475560889\n",
      "0.3207067608614502\n",
      "0.2871119248200538\n",
      "0.3943238472952454\n",
      "0.28961920157663024\n",
      "0.3553792351662484\n",
      "0.20311910441203893\n",
      "0.23213900942875965\n",
      "0.22179017971650022\n",
      "0.19471163729855792\n",
      "0.22061951948449718\n",
      "0.4152636184274482\n",
      "0.3343118819426021\n",
      "0.23348759821555992\n",
      "0.14629069046590007\n",
      "0.21106521850366813\n",
      "0.26221218552665526\n",
      "0.31425140707530497\n",
      "0.34810855855273276\n",
      "0.24592409428207673\n",
      "0.23682205532137024\n",
      "0.237599222473006\n",
      "0.2971388993218024\n",
      "[[9.97375728e-01 1.33694805e-01 2.02190702e-07]\n",
      " [9.97824862e-01 1.22962557e-01 1.40787772e-07]\n",
      " [9.64918989e-01 3.36781197e-01 2.74073731e-05]\n",
      " [9.97057748e-01 1.69544688e-01 3.46391885e-07]\n",
      " [9.89079365e-01 1.32614600e-01 1.20502475e-06]\n",
      " [9.95845924e-01 1.00684593e-01 2.33149812e-07]\n",
      " [9.91780307e-01 1.95162464e-01 1.57621822e-06]\n",
      " [9.98799313e-01 9.44699249e-02 4.46942314e-08]\n",
      " [9.96507343e-01 1.67210081e-01 4.17956979e-07]\n",
      " [9.98695073e-01 9.96162855e-02 5.34697463e-08]\n",
      " [9.97188313e-01 1.46082701e-01 2.54048117e-07]\n",
      " [1.17543810e-02 3.72769857e-01 3.47993788e-01]\n",
      " [1.13475581e-02 3.57525613e-01 3.37714547e-01]\n",
      " [9.64735170e-03 2.64771728e-01 2.55382001e-01]\n",
      " [2.12232421e-02 3.35868285e-01 1.67347571e-01]\n",
      " [6.86043165e-02 4.05556539e-01 6.23735635e-02]\n",
      " [1.35378222e-02 3.29239396e-01 2.55755568e-01]\n",
      " [3.89509649e-02 2.60047249e-01 5.32992008e-02]\n",
      " [2.14487061e-02 2.83211577e-01 1.24615669e-01]\n",
      " [1.78693608e-02 2.71004543e-01 1.40558173e-01]\n",
      " [1.16030810e-01 3.49368625e-01 2.28022307e-02]\n",
      " [1.99513098e-02 3.01465749e-01 1.49635441e-01]\n",
      " [2.29166208e-04 2.63959997e-01 9.73320590e-01]\n",
      " [5.37475012e-05 2.84513814e-01 9.96150735e-01]\n",
      " [1.75182313e-04 2.62707725e-01 9.80652369e-01]\n",
      " [3.25257339e-04 3.70668869e-01 9.79258714e-01]\n",
      " [6.07341531e-05 2.65895526e-01 9.94900710e-01]\n",
      " [5.02228671e-05 2.50583182e-01 9.95533838e-01]\n",
      " [1.18662474e-04 2.91422752e-01 9.90159026e-01]\n",
      " [2.32917429e-04 3.98006923e-01 9.88077898e-01]\n",
      " [3.72453411e-04 2.87598558e-01 9.59242618e-01]\n",
      " [2.26009818e-04 2.32648623e-01 9.67834924e-01]\n",
      " [9.59965406e-04 2.96620244e-01 8.85518005e-01]]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "x_batch, y_batch = mini_batch(batch_size, data_x, data_y)\n",
    "\n",
    "x = Input(x_batch)\n",
    "l2 = Dense(x, 4)\n",
    "# l3 = Dense(l2, 10)\n",
    "# l3 = Sigmoid(l3)\n",
    "l4 = Dense(l2, 3)\n",
    "l4 = Sigmoid(l4)\n",
    "\n",
    "\n",
    "y = Const(y_batch)\n",
    "cost = MSE(l4, y)\n",
    "\n",
    "Forward(cost)\n",
    "p = Backprop(cost)\n",
    "GD = G_D_Optimizer(p, 0.01, 3) # lr; step\n",
    "print(cost.value)\n",
    "epoch = 1500\n",
    "for ep in range(epoch):\n",
    "    x_batch, y_batch = mini_batch(batch_size, data_x,data_y)\n",
    "    x.value = x_batch\n",
    "    y.value = y_batch\n",
    "    Forward(cost)\n",
    "    Backprop(cost)\n",
    "    GD.train()\n",
    "    if ep % 50 == 0:\n",
    "        print(cost.value)\n",
    "#\n",
    "#test = preprocessing.MinMaxScaler().fit_transform(np.array([[5.1,3.4,1.5,0.2]]))\n",
    "# x.value = np.array([[5.1,3.4,1.5,0.2]])\n",
    "# x.value = test\n",
    "x.value = x_test\n",
    "Forward(cost)\n",
    "# Backprop(cost)\n",
    "print(cost.value)\n",
    "print(l4.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-2236aafba4ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;31m# y = np.array([[0],[0],[1],[0]])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m     \u001b[0mNN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[0mNN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_x' is not defined"
     ]
    }
   ],
   "source": [
    "def activation_function(choice, x):  # activation function ,output vector or num, x is a matrices\n",
    "    if choice == 1:  # sigmoid\n",
    "\n",
    "        return 1.0 / (1 + np.exp(-x))\n",
    "    else:\n",
    "        return np.maximum(x, 0.0)  # relu\n",
    "        # return abs(x)\n",
    "\n",
    "\n",
    "def function_derivative(choice, x):\n",
    "    derivative = np.zeros([1, x.shape[1]])\n",
    "    if choice == 1:\n",
    "        return np.multiply((1 / (1 + np.exp(-x))), (1 - 1 / (1 + np.exp(-x))))  # 此处用点乘 * 不行，要用multiply       sigmoid\n",
    "    else:\n",
    "        for i in range(x.shape[1]):\n",
    "            if x[0, i] > 0:\n",
    "                derivative[0, i] = 1\n",
    "            else:\n",
    "                derivative[0, i] = 0\n",
    "        return derivative\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, x, y, alpha=0.01):  # 输入矩阵行都是行向量属性，列是样本数\n",
    "        self.input = x\n",
    "        self.y = y\n",
    "        self.hidden_neuron_num = 4\n",
    "        self.choice = 2  # 1:sigmoid, 2:relu,第一层用choice，第二层choice2\n",
    "        self.choice2 = 1\n",
    "        self.weights1 = np.random.rand(self.input.shape[1],\n",
    "                                       self.hidden_neuron_num)  # 1*4     #initialize layer1 weights,hidden_neutal == 4 ,是矩阵\n",
    "        # self.weights1 = np.random.uniform(1,50,(1,4))\n",
    "        self.weights2 = np.random.rand(self.hidden_neuron_num, self.y.shape[1])  # 4*1\n",
    "        # self.weights2 = np.random.uniform(1,50,(4,1))\n",
    "        self.bias1 = np.random.rand(1, 1)\n",
    "        # self.bias1 = np.array([[0.1]])\n",
    "        self.bias2 = np.random.rand(1, 1)\n",
    "        # self.bias2 = np.array([[0.1]])\n",
    "        self.output = np.zeros(self.y.shape[1])  # initialize output\n",
    "        self.learning_rate = alpha\n",
    "        self.loss = 0\n",
    "\n",
    "    def feedforward(self, current_x):\n",
    "        self.layer1 = activation_function(self.choice, np.dot(current_x, self.weights1) + self.bias1 * np.ones(\n",
    "            self.hidden_neuron_num))  # current_x:1*1,self.weights:1*4,hidden_neural == 4\n",
    "        self.output = activation_function(self.choice2,\n",
    "                                          np.dot(self.layer1, self.weights2) + self.bias2 * np.ones(self.y.shape[1]))\n",
    "\n",
    "    def backpropagation(self, current_x, current_y):\n",
    "        d_weights2 = np.dot(self.layer1.T, np.multiply(2 * (self.output - mat(current_y)),\n",
    "                                                       function_derivative(self.choice2,\n",
    "                                                                           self.output)))  # 这里的 *是点乘，适合输出为多维情况\n",
    "        d_weights1 = np.dot(mat(current_x).T, np.multiply(\n",
    "            np.dot(np.multiply(function_derivative(self.choice2, self.output), 2 * (self.output - mat(current_y))),\n",
    "                   self.weights2.T), function_derivative(self.choice, self.layer1)))\n",
    "        d_bias2 = np.dot(2 * (self.output - mat(current_y)), function_derivative(self.choice, self.output).T)\n",
    "        d_bias1 = np.dot(\n",
    "            np.dot(np.multiply(function_derivative(self.choice, self.output), 2 * (self.output - mat(current_y))),\n",
    "                   self.weights2.T), function_derivative(self.choice, self.layer1).T)\n",
    "\n",
    "        # update weights and bias\n",
    "        self.weights1 -= self.learning_rate * d_weights1\n",
    "        self.weights2 -= self.learning_rate * d_weights2\n",
    "        self.bias1 -= self.learning_rate * d_bias1\n",
    "        self.bias2 -= self.learning_rate * d_bias2\n",
    "\n",
    "    # def train(self):\n",
    "    #     #         batch = 30\n",
    "    #     #         i = random.randint(0,120)\n",
    "    #     for i in range(self.input.shape[0]):\n",
    "    #         self.feedforward(self.input[i])\n",
    "    #         self.backpropagation(self.input[i], self.y[i])\n",
    "    #         #         for i in range(self.input.shape[0]):\n",
    "    #         #             self.feedforward(self.input[i])\n",
    "    #         self.loss += np.sum(np.square(self.output - self.y[i])) / self.input.shape[0]\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        for i in range(self.input.shape[0]):\n",
    "            self.feedforward(self.input[i])\n",
    "            self.backpropagation(self.input[i], self.y[i])\n",
    "        for j in range(self.input.shape[0]):\n",
    "            self.feedforward(self.input[j])\n",
    "            self.loss += np.sum(np.square(self.output - self.y[j])) / self.input.shape[0]\n",
    "\n",
    "    def test(self, test_x, test_y):\n",
    "        prediction = np.zeros((test_y.shape[0], test_y.shape[1]))\n",
    "        for i in range(test_x.shape[0]):\n",
    "            self.feedforward(test_x[i])\n",
    "            prediction[i] = self.output[0]\n",
    "        print(prediction)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # x = np.linspace(-1,1,num = 300)[:,np.newaxis]\n",
    "    # noise = np.random.normal(0, 0.05, x.shape).astype(np.float32)\n",
    "    # y = np.square(x) - 0.5 + noise\n",
    "\n",
    "    #     x = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
    "    #     y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "    #     x_test = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1],[0, 1, 1],[[1, 1, 0]]])\n",
    "    #     y_test = np.array([[0],[1],[1],[0],[1],[0]])\n",
    "    # x = np.array([[0,0],[1,0],[1,1],[0,1]])\n",
    "    # y = np.array([[0],[0],[1],[0]])\n",
    "\n",
    "    NN = NeuralNetwork(data_x, data_y)\n",
    "    for j in range(1500):\n",
    "        NN.loss = 0\n",
    "        NN.train()\n",
    "\n",
    "        if j % 50 == 0:\n",
    "            print(NN.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.99857887e-01 3.84044507e-04 8.29003976e-17]\n",
      " [9.99964249e-01 1.94973943e-04 4.13725407e-17]\n",
      " [9.50045373e-01 2.31080208e-02 2.31499718e-08]\n",
      " [9.99789115e-01 8.19489762e-04 2.12752855e-13]\n",
      " [9.99067007e-01 1.27976477e-03 9.47807186e-15]\n",
      " [9.99531377e-01 6.59359421e-04 8.14984014e-17]\n",
      " [9.98570143e-01 2.02660812e-03 3.50468545e-13]\n",
      " [9.99972417e-01 1.32145683e-04 1.04675023e-18]\n",
      " [9.99653273e-01 9.40042755e-04 6.40803413e-14]\n",
      " [9.99978390e-01 1.06771132e-04 2.61172693e-19]\n",
      " [9.99858351e-01 4.28637056e-04 3.75248028e-16]\n",
      " [6.73314318e-07 9.93360447e-01 1.03444385e-02]\n",
      " [2.16696170e-07 9.95927852e-01 7.55017396e-03]\n",
      " [2.14761147e-08 9.97099199e-01 1.01729341e-02]\n",
      " [1.59154456e-07 9.96435955e-01 6.92897827e-03]\n",
      " [1.80754385e-05 9.72928142e-01 2.56074936e-02]\n",
      " [2.33214036e-07 9.95796644e-01 7.70599943e-03]\n",
      " [3.00808150e-07 9.94415666e-01 7.75686844e-04]\n",
      " [1.24992208e-07 9.96789235e-01 6.47829008e-03]\n",
      " [9.09345164e-08 9.96011793e-01 1.60185779e-04]\n",
      " [4.33631879e-05 9.56689919e-01 7.77192863e-03]\n",
      " [1.74412925e-07 9.96292202e-01 7.10776064e-03]\n",
      " [1.28139910e-10 1.11050026e-08 9.99999960e-01]\n",
      " [9.40297194e-11 9.85569718e-15 1.00000000e+00]\n",
      " [3.11623056e-10 9.38780253e-09 9.99999959e-01]\n",
      " [6.31553796e-09 4.81066569e-10 9.99999984e-01]\n",
      " [2.93457208e-11 5.03117662e-15 1.00000000e+00]\n",
      " [7.08410553e-11 8.14886127e-16 1.00000000e+00]\n",
      " [3.62495915e-10 8.41111143e-11 9.99999999e-01]\n",
      " [2.02290042e-09 3.18268641e-08 9.99999594e-01]\n",
      " [7.48912364e-10 6.58360112e-08 9.99999679e-01]\n",
      " [9.05680060e-10 1.77067742e-12 1.00000000e+00]\n",
      " [6.05938601e-09 5.09756481e-07 9.99996694e-01]]\n"
     ]
    }
   ],
   "source": [
    "NN.test(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.60346339, 0.55294892, 0.56598759, 0.00463989],\n",
       "       [0.29861183, 0.61777568, 0.96514733, 0.00568809],\n",
       "       [0.90294718, 0.57296699, 0.29898411, 0.82365922]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
