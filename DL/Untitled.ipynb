{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2021/4/10 18:08\n",
    "# @Author  : Weiming Mai\n",
    "# @FileName: main.py\n",
    "# @Software: PyCharm\n",
    "\n",
    "import numpy as np\n",
    "from Nodes import *\n",
    "from Utils import *\n",
    "from numpy import *\n",
    "import xlrd\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "def excel_to_matrix(path, num):\n",
    "    table = xlrd.open_workbook(path).sheets()[num]  # 获取第一个sheet表\n",
    "    row = table.nrows  # 行数\n",
    "    col = table.ncols  # 列数\n",
    "    datamatrix = np.zeros((row, col))  # 生成一个nrows行ncols列，且元素均为0的初始矩阵\n",
    "    for x in range(col):\n",
    "        cols = np.matrix(table.col_values(x))  # 把list转换为矩阵进行矩阵操作\n",
    "        datamatrix[:, x] = cols  # 按列把数据存进矩阵中\n",
    "        # 数据归一化\n",
    "#         min_max_scaler = preprocessing.MinMaxScaler()\n",
    "#         datamatrix = min_max_scaler.fit_transform(datamatrix)\n",
    "    return datamatrix\n",
    "\n",
    "def mini_batch(batch_size, data_X, data_Y):\n",
    "    idx = np.arange(0, data_X.shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[0:batch_size]\n",
    "\n",
    "    return data_X[idx,:], data_Y[idx,:]\n",
    "\n",
    "datafile = \"C:/Users/13271/Desktop/git/DL/iris_test+train.xlsx\"\n",
    "\n",
    "data_x = excel_to_matrix(datafile, 0)\n",
    "data_y = excel_to_matrix(datafile, 3)\n",
    "\n",
    "x_test = excel_to_matrix(datafile, 1)\n",
    "y_test = excel_to_matrix(datafile, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1551765590257501\n",
      "0.6229959980761539\n",
      "0.3217309450208431\n",
      "0.3589071310697268\n",
      "0.2555589671277351\n",
      "0.36352525159706406\n",
      "0.24788280888936756\n",
      "0.28845979729385657\n",
      "0.2872466525991918\n",
      "0.2563846507068324\n",
      "0.26929997621118934\n",
      "0.31393571012276517\n",
      "[[ 0.94002509  0.22015312 -0.1601703 ]\n",
      " [ 1.00238934  0.10856725 -0.11095218]\n",
      " [ 0.60290068  0.71185191 -0.31476261]\n",
      " [ 0.90161166  0.23532534 -0.13694537]\n",
      " [ 0.92033789  0.04764364  0.03201652]\n",
      " [ 0.97614702 -0.02324084  0.04709796]\n",
      " [ 0.81642415  0.3692819  -0.18570769]\n",
      " [ 1.05051032  0.00895502 -0.05945673]\n",
      " [ 0.8855677   0.26597294 -0.15154459]\n",
      " [ 1.04125415  0.07766735 -0.11890823]\n",
      " [ 0.92534135  0.25552388 -0.18085964]\n",
      " [ 0.07830172  0.65324082  0.26844601]\n",
      " [ 0.03987738  0.6607436   0.29936874]\n",
      " [ 0.12617913  0.46719303  0.40662822]\n",
      " [ 0.12395432  0.66040565  0.21563767]\n",
      " [ 0.1648828   0.73472459  0.10037635]\n",
      " [ 0.10586001  0.57138545  0.32274541]\n",
      " [ 0.21296802  0.44651357  0.34051419]\n",
      " [ 0.17274298  0.47269031  0.35456036]\n",
      " [ 0.16212659  0.53667948  0.30119898]\n",
      " [ 0.28306466  0.58204206  0.13487863]\n",
      " [ 0.15986843  0.51917493  0.3209503 ]\n",
      " [-0.03792618  0.36746419  0.67046614]\n",
      " [-0.10393367  0.27589299  0.82803406]\n",
      " [ 0.00568456  0.28474904  0.70956748]\n",
      " [-0.11361153  0.4970256   0.61656804]\n",
      " [-0.12088647  0.28608975  0.83479384]\n",
      " [-0.06621036  0.14577613  0.92042596]\n",
      " [-0.05013305  0.3258457   0.72428331]\n",
      " [-0.14997703  0.653984    0.49598654]\n",
      " [-0.03068701  0.38980124  0.64088273]\n",
      " [ 0.03164389  0.0674982   0.90084272]\n",
      " [-0.00650353  0.37215372  0.63433682]]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "x_batch, y_batch = mini_batch(batch_size, data_x, data_y)\n",
    "\n",
    "x = Input(x_batch)\n",
    "l2 = Dense(x, 6)\n",
    "# l2 = Sigmoid(l2)\n",
    "l3 = Dense(l2, 4)\n",
    "# l3 = Sigmoid(l3)\n",
    "l4 = Dense(l3, 4)\n",
    "# l4 = Sigmoid(l4)\n",
    "l5 = Dense(l4, 3)\n",
    "# l5 = Sigmoid(l5)\n",
    "\n",
    "\n",
    "y = Const(y_batch)\n",
    "cost = MSE(l5, y)\n",
    "\n",
    "Forward(cost)\n",
    "p = Backprop(cost)\n",
    "GD = G_D_Optimizer(p, 0.005) # lr\n",
    "print(cost.value)\n",
    "epoch = 1000\n",
    "for ep in range(epoch):\n",
    "    x_batch, y_batch = mini_batch(batch_size, data_x,data_y)\n",
    "    x.value = x_batch\n",
    "    y.value = y_batch\n",
    "    for j in range(20):\n",
    "        Forward(cost)\n",
    "        Backprop(cost)\n",
    "        GD.train()\n",
    "    if ep % 100 == 0:\n",
    "        print(cost.value)\n",
    "#\n",
    "#test = preprocessing.MinMaxScaler().fit_transform(np.array([[5.1,3.4,1.5,0.2]]))\n",
    "# x.value = np.array([[5.1,3.4,1.5,0.2]])\n",
    "# x.value = test\n",
    "x.value = x_test\n",
    "Forward(cost)\n",
    "# Backprop(cost)\n",
    "print(cost.value)\n",
    "print(l5.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6671848785796811\n",
      "0.5750518878054989\n",
      "0.6311979863149375\n",
      "0.6251713211083346\n",
      "0.5497766531106618\n",
      "0.467578016527202\n",
      "0.41063521828971916\n",
      "0.3772833736570787\n",
      "0.355216224592068\n",
      "0.3409338205110204\n",
      "0.33117208215204097\n",
      "0.3241953154268692\n",
      "0.31963446159142406\n",
      "0.316259545971314\n",
      "0.31378652669672497\n",
      "0.31195329307644976\n",
      "0.31054097889955284\n",
      "0.30956193292426726\n",
      "0.30874693841406\n",
      "0.3081423369475739\n",
      "0.30766886141573047\n",
      "0.30729748143627234\n",
      "0.3070044701484074\n",
      "0.3067709983709008\n",
      "0.3065801113675294\n",
      "0.3064200394154444\n",
      "0.3062800722364157\n",
      "0.3061506537624774\n",
      "0.306023580804198\n",
      "0.30589188954856505\n"
     ]
    }
   ],
   "source": [
    "def activation_function(choice, x):  # activation function ,output vector or num, x is a matrices\n",
    "    if choice == 1:  # sigmoid\n",
    "\n",
    "        return 1.0 / (1 + np.exp(-x))\n",
    "    else:\n",
    "        return np.maximum(x, 0.0)  # relu\n",
    "        # return abs(x)\n",
    "\n",
    "\n",
    "def function_derivative(choice, x):\n",
    "    derivative = np.zeros([1, x.shape[1]])\n",
    "    if choice == 1:\n",
    "        return np.multiply((1 / (1 + np.exp(-x))), (1 - 1 / (1 + np.exp(-x))))  # 此处用点乘 * 不行，要用multiply       sigmoid\n",
    "    else:\n",
    "        for i in range(x.shape[1]):\n",
    "            if x[0, i] > 0:\n",
    "                derivative[0, i] = 1\n",
    "            else:\n",
    "                derivative[0, i] = 0\n",
    "        return derivative\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, x, y, alpha=0.01):  # 输入矩阵行都是行向量属性，列是样本数\n",
    "        self.input = x\n",
    "        self.y = y\n",
    "        self.hidden_neuron_num = 4\n",
    "        self.choice = 2  # 1:sigmoid, 2:relu,第一层用choice，第二层choice2\n",
    "        self.choice2 = 1\n",
    "        self.weights1 = np.random.rand(self.input.shape[1],\n",
    "                                       self.hidden_neuron_num)  # 1*4     #initialize layer1 weights,hidden_neutal == 4 ,是矩阵\n",
    "        # self.weights1 = np.random.uniform(1,50,(1,4))\n",
    "        self.weights2 = np.random.rand(self.hidden_neuron_num, self.y.shape[1])  # 4*1\n",
    "        # self.weights2 = np.random.uniform(1,50,(4,1))\n",
    "        self.bias1 = np.random.rand(1, 1)\n",
    "        # self.bias1 = np.array([[0.1]])\n",
    "        self.bias2 = np.random.rand(1, 1)\n",
    "        # self.bias2 = np.array([[0.1]])\n",
    "        self.output = np.zeros(self.y.shape[1])  # initialize output\n",
    "        self.learning_rate = alpha\n",
    "        self.loss = 0\n",
    "\n",
    "    def feedforward(self, current_x):\n",
    "        self.layer1 = activation_function(self.choice, np.dot(current_x, self.weights1) + self.bias1 * np.ones(\n",
    "            self.hidden_neuron_num))  # current_x:1*1,self.weights:1*4,hidden_neural == 4\n",
    "        self.output = activation_function(self.choice2,\n",
    "                                          np.dot(self.layer1, self.weights2) + self.bias2 * np.ones(self.y.shape[1]))\n",
    "\n",
    "    def backpropagation(self, current_x, current_y):\n",
    "        d_weights2 = np.dot(self.layer1.T, np.multiply(2 * (self.output - mat(current_y)),\n",
    "                                                       function_derivative(self.choice2,\n",
    "                                                                           self.output)))  # 这里的 *是点乘，适合输出为多维情况\n",
    "        d_weights1 = np.dot(mat(current_x).T, np.multiply(\n",
    "            np.dot(np.multiply(function_derivative(self.choice2, self.output), 2 * (self.output - mat(current_y))),\n",
    "                   self.weights2.T), function_derivative(self.choice, self.layer1)))\n",
    "        d_bias2 = np.dot(2 * (self.output - mat(current_y)), function_derivative(self.choice, self.output).T)\n",
    "        d_bias1 = np.dot(\n",
    "            np.dot(np.multiply(function_derivative(self.choice, self.output), 2 * (self.output - mat(current_y))),\n",
    "                   self.weights2.T), function_derivative(self.choice, self.layer1).T)\n",
    "\n",
    "        # update weights and bias\n",
    "        self.weights1 -= self.learning_rate * d_weights1\n",
    "        self.weights2 -= self.learning_rate * d_weights2\n",
    "        self.bias1 -= self.learning_rate * d_bias1\n",
    "        self.bias2 -= self.learning_rate * d_bias2\n",
    "\n",
    "    # def train(self):\n",
    "    #     #         batch = 30\n",
    "    #     #         i = random.randint(0,120)\n",
    "    #     for i in range(self.input.shape[0]):\n",
    "    #         self.feedforward(self.input[i])\n",
    "    #         self.backpropagation(self.input[i], self.y[i])\n",
    "    #         #         for i in range(self.input.shape[0]):\n",
    "    #         #             self.feedforward(self.input[i])\n",
    "    #         self.loss += np.sum(np.square(self.output - self.y[i])) / self.input.shape[0]\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        for i in range(self.input.shape[0]):\n",
    "            self.feedforward(self.input[i])\n",
    "            self.backpropagation(self.input[i], self.y[i])\n",
    "        for j in range(self.input.shape[0]):\n",
    "            self.feedforward(self.input[j])\n",
    "            self.loss += np.sum(np.square(self.output - self.y[j])) / self.input.shape[0]\n",
    "\n",
    "    def test(self, test_x, test_y):\n",
    "        prediction = np.zeros((test_y.shape[0], test_y.shape[1]))\n",
    "        for i in range(test_x.shape[0]):\n",
    "            self.feedforward(test_x[i])\n",
    "            prediction[i] = self.output[0]\n",
    "        print(prediction)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # x = np.linspace(-1,1,num = 300)[:,np.newaxis]\n",
    "    # noise = np.random.normal(0, 0.05, x.shape).astype(np.float32)\n",
    "    # y = np.square(x) - 0.5 + noise\n",
    "\n",
    "    #     x = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
    "    #     y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "    #     x_test = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1],[0, 1, 1],[[1, 1, 0]]])\n",
    "    #     y_test = np.array([[0],[1],[1],[0],[1],[0]])\n",
    "    # x = np.array([[0,0],[1,0],[1,1],[0,1]])\n",
    "    # y = np.array([[0],[0],[1],[0]])\n",
    "\n",
    "    NN = NeuralNetwork(data_x, data_y)\n",
    "    for j in range(1500):\n",
    "        NN.loss = 0\n",
    "        NN.train()\n",
    "\n",
    "        if j % 50 == 0:\n",
    "            print(NN.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.37534711e-01 3.37534711e-01 3.37534711e-01]\n",
      " [3.37534711e-01 3.37534711e-01 3.37534711e-01]\n",
      " [3.37534711e-01 3.37534711e-01 3.37534711e-01]\n",
      " [3.37534711e-01 3.37534711e-01 3.37534711e-01]\n",
      " [3.37534711e-01 3.37534711e-01 3.37534711e-01]\n",
      " [3.37534711e-01 3.37534711e-01 3.37534711e-01]\n",
      " [3.37534711e-01 3.37534711e-01 3.37534711e-01]\n",
      " [3.37534711e-01 3.37534711e-01 3.37534711e-01]\n",
      " [3.37534711e-01 3.37534711e-01 3.37534711e-01]\n",
      " [3.37534711e-01 3.37534711e-01 3.37534711e-01]\n",
      " [3.37534711e-01 3.37534711e-01 3.37534711e-01]\n",
      " [5.40836029e-07 9.56945771e-01 3.81545370e-02]\n",
      " [2.06345815e-07 6.88860237e-01 2.58818671e-01]\n",
      " [1.24808778e-10 9.63484494e-01 4.40104829e-02]\n",
      " [1.22575978e-07 9.99880293e-01 1.60035337e-04]\n",
      " [5.11474666e-03 9.20558062e-01 3.64223810e-02]\n",
      " [7.60326316e-08 9.71038636e-01 2.78352190e-02]\n",
      " [3.68772455e-08 9.99937634e-01 9.14787560e-05]\n",
      " [2.22412927e-08 9.98914344e-01 1.32277098e-03]\n",
      " [5.62743748e-10 9.99919730e-01 1.35308832e-04]\n",
      " [2.31911210e-03 9.52097631e-01 2.35526243e-02]\n",
      " [4.26009483e-08 9.99111004e-01 1.08057550e-03]\n",
      " [1.02783312e-16 8.28738267e-08 9.99999880e-01]\n",
      " [1.75957578e-17 1.06897478e-12 1.00000000e+00]\n",
      " [6.41217903e-17 7.21513043e-08 9.99999899e-01]\n",
      " [6.71618402e-12 5.13629881e-10 9.99999998e-01]\n",
      " [4.99463173e-18 1.02213933e-12 1.00000000e+00]\n",
      " [3.15409336e-18 3.23710222e-13 1.00000000e+00]\n",
      " [2.21887942e-16 9.56412577e-10 9.99999998e-01]\n",
      " [6.23435794e-13 1.03748528e-08 9.99999976e-01]\n",
      " [8.80261562e-15 1.58859595e-07 9.99999732e-01]\n",
      " [9.39850859e-16 1.35360991e-10 1.00000000e+00]\n",
      " [3.24536852e-12 4.64641046e-07 9.99999031e-01]]\n"
     ]
    }
   ],
   "source": [
    "NN.test(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.60346339, 0.55294892, 0.56598759, 0.00463989],\n",
       "       [0.29861183, 0.61777568, 0.96514733, 0.00568809],\n",
       "       [0.90294718, 0.57296699, 0.29898411, 0.82365922]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
