{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2021/4/10 18:08\n",
    "# @Author  : Weiming Mai\n",
    "# @FileName: main.py\n",
    "# @Software: PyCharm\n",
    "\n",
    "import numpy as np\n",
    "from Nodes import *\n",
    "from Utils import *\n",
    "from numpy import *\n",
    "import xlrd\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "def excel_to_matrix(path, num):\n",
    "    table = xlrd.open_workbook(path).sheets()[num]  # 获取第一个sheet表\n",
    "    row = table.nrows  # 行数\n",
    "    col = table.ncols  # 列数\n",
    "    datamatrix = np.zeros((row, col))  # 生成一个nrows行ncols列，且元素均为0的初始矩阵\n",
    "    for x in range(col):\n",
    "        cols = np.matrix(table.col_values(x))  # 把list转换为矩阵进行矩阵操作\n",
    "        datamatrix[:, x] = cols  # 按列把数据存进矩阵中\n",
    "        # 数据归一化\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        datamatrix = min_max_scaler.fit_transform(datamatrix)\n",
    "    return datamatrix\n",
    "\n",
    "def mini_batch(batch_size, data_X, data_Y):\n",
    "    idx = np.arange(0, data_X.shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[0:batch_size]\n",
    "\n",
    "    return data_X[idx,:], data_Y[idx,:]\n",
    "\n",
    "datafile = \"C:/Users/13271/Desktop/git/DL/iris_test+train.xlsx\"\n",
    "\n",
    "data_x = excel_to_matrix(datafile, 0)\n",
    "data_y = excel_to_matrix(datafile, 3)\n",
    "\n",
    "x_test = excel_to_matrix(datafile, 1)\n",
    "y_test = excel_to_matrix(datafile, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1081623319125744\n",
      "0.6619803915781409\n",
      "0.23430378013100348\n",
      "0.2105923267776595\n",
      "0.24104673591461737\n",
      "0.16673921037448197\n",
      "0.30783438098942395\n",
      "0.2671147918731628\n",
      "0.2883287962891622\n",
      "0.29619280720451874\n",
      "0.2483742629483443\n",
      "1.0653659646137814\n",
      "[[ 1.10154793  0.03979461 -0.1414362 ]\n",
      " [ 1.17712427 -0.09897933 -0.07820734]\n",
      " [ 0.61324372  0.77605362 -0.3889271 ]\n",
      " [ 1.03045235  0.06258759 -0.09301044]\n",
      " [ 1.0745694  -0.1800865   0.10549347]\n",
      " [ 1.16980922 -0.32865861  0.15860852]\n",
      " [ 0.91983815  0.27132152 -0.19105883]\n",
      " [ 1.26081761 -0.27874042  0.01767286]\n",
      " [ 1.01507629  0.1039536  -0.11902285]\n",
      " [ 1.24524148 -0.16500885 -0.08043658]\n",
      " [ 1.07507817  0.09770704 -0.17282437]\n",
      " [ 0.01380608  0.60102138  0.38528856]\n",
      " [-0.01972435  0.56815131  0.45155731]\n",
      " [ 0.11560116  0.30302985  0.58122262]\n",
      " [ 0.08172322  0.60735742  0.31096229]\n",
      " [ 0.09780476  0.73382777  0.16859577]\n",
      " [ 0.0631144   0.46659013  0.47030533]\n",
      " [ 0.21472321  0.27436927  0.51078021]\n",
      " [ 0.15769969  0.32385236  0.51838522]\n",
      " [ 0.15321726  0.42103751  0.42565156]\n",
      " [ 0.24875904  0.54744126  0.2040355 ]\n",
      " [ 0.13486114  0.40037118  0.46475662]\n",
      " [-0.07180529  0.18611199  0.88556309]\n",
      " [-0.1589841   0.06363881  1.0952763 ]\n",
      " [-0.02698278  0.11127426  0.91568809]\n",
      " [-0.20264837  0.35404831  0.84863144]\n",
      " [-0.16624483  0.04522186  1.1208362 ]\n",
      " [-0.10221497 -0.12474106  1.22683022]\n",
      " [-0.10236072  0.15888683  0.94347722]\n",
      " [-0.25280792  0.60427108  0.64864059]\n",
      " [-0.07498373  0.21524102  0.85966257]\n",
      " [ 0.01611442 -0.24852682  1.23225683]\n",
      " [-0.05103957  0.16182746  0.88910633]]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "x_batch, y_batch = mini_batch(batch_size, data_x, data_y)\n",
    "\n",
    "x = Input(x_batch)\n",
    "l2 = Dense(x, 6)\n",
    "# l2 = Sigmoid(l2)\n",
    "l3 = Dense(l2, 4)\n",
    "# l3 = Sigmoid(l3)\n",
    "l4 = Dense(l3, 4)\n",
    "# l4 = Sigmoid(l4)\n",
    "l5 = Dense(l4, 3)\n",
    "# l5 = Sigmoid(l5)\n",
    "\n",
    "\n",
    "y = Const(y_batch)\n",
    "cost = MSE(l5, y)\n",
    "\n",
    "Forward(cost)\n",
    "p = Backprop(cost)\n",
    "GD = G_D_Optimizer(p, 0.005) # lr\n",
    "print(cost.value)\n",
    "epoch = 1000\n",
    "for ep in range(epoch):\n",
    "    x_batch, y_batch = mini_batch(batch_size, data_x,data_y)\n",
    "    x.value = x_batch\n",
    "    y.value = y_batch\n",
    "    for j in range(20):\n",
    "        Forward(cost)\n",
    "        Backprop(cost)\n",
    "        GD.train()\n",
    "    if ep % 100 == 0:\n",
    "        print(cost.value)\n",
    "#\n",
    "#test = preprocessing.MinMaxScaler().fit_transform(np.array([[5.1,3.4,1.5,0.2]]))\n",
    "# x.value = np.array([[5.1,3.4,1.5,0.2]])\n",
    "# x.value = test\n",
    "x.value = x_test\n",
    "Forward(cost)\n",
    "# Backprop(cost)\n",
    "print(cost.value)\n",
    "print(l5.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6671848785796811\n",
      "0.5750518878054989\n",
      "0.6311979863149375\n",
      "0.6251713211083346\n",
      "0.5497766531106618\n",
      "0.467578016527202\n",
      "0.41063521828971916\n",
      "0.3772833736570787\n",
      "0.355216224592068\n",
      "0.3409338205110204\n",
      "0.33117208215204097\n",
      "0.3241953154268692\n",
      "0.31963446159142406\n",
      "0.316259545971314\n",
      "0.31378652669672497\n",
      "0.31195329307644976\n",
      "0.31054097889955284\n",
      "0.30956193292426726\n",
      "0.30874693841406\n",
      "0.3081423369475739\n",
      "0.30766886141573047\n",
      "0.30729748143627234\n",
      "0.3070044701484074\n",
      "0.3067709983709008\n",
      "0.3065801113675294\n",
      "0.3064200394154444\n",
      "0.3062800722364157\n",
      "0.3061506537624774\n",
      "0.306023580804198\n",
      "0.30589188954856505\n"
     ]
    }
   ],
   "source": [
    "def activation_function(choice, x):  # activation function ,output vector or num, x is a matrices\n",
    "    if choice == 1:  # sigmoid\n",
    "\n",
    "        return 1.0 / (1 + np.exp(-x))\n",
    "    else:\n",
    "        return np.maximum(x, 0.0)  # relu\n",
    "        # return abs(x)\n",
    "\n",
    "\n",
    "def function_derivative(choice, x):\n",
    "    derivative = np.zeros([1, x.shape[1]])\n",
    "    if choice == 1:\n",
    "        return np.multiply((1 / (1 + np.exp(-x))), (1 - 1 / (1 + np.exp(-x))))  # 此处用点乘 * 不行，要用multiply       sigmoid\n",
    "    else:\n",
    "        for i in range(x.shape[1]):\n",
    "            if x[0, i] > 0:\n",
    "                derivative[0, i] = 1\n",
    "            else:\n",
    "                derivative[0, i] = 0\n",
    "        return derivative\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, x, y, alpha=0.01):  # 输入矩阵行都是行向量属性，列是样本数\n",
    "        self.input = x\n",
    "        self.y = y\n",
    "        self.hidden_neuron_num = 4\n",
    "        self.choice = 2  # 1:sigmoid, 2:relu,第一层用choice，第二层choice2\n",
    "        self.choice2 = 1\n",
    "        self.weights1 = np.random.rand(self.input.shape[1],\n",
    "                                       self.hidden_neuron_num)  # 1*4     #initialize layer1 weights,hidden_neutal == 4 ,是矩阵\n",
    "        # self.weights1 = np.random.uniform(1,50,(1,4))\n",
    "        self.weights2 = np.random.rand(self.hidden_neuron_num, self.y.shape[1])  # 4*1\n",
    "        # self.weights2 = np.random.uniform(1,50,(4,1))\n",
    "        self.bias1 = np.random.rand(1, 1)\n",
    "        # self.bias1 = np.array([[0.1]])\n",
    "        self.bias2 = np.random.rand(1, 1)\n",
    "        # self.bias2 = np.array([[0.1]])\n",
    "        self.output = np.zeros(self.y.shape[1])  # initialize output\n",
    "        self.learning_rate = alpha\n",
    "        self.loss = 0\n",
    "\n",
    "    def feedforward(self, current_x):\n",
    "        self.layer1 = activation_function(self.choice, np.dot(current_x, self.weights1) + self.bias1 * np.ones(\n",
    "            self.hidden_neuron_num))  # current_x:1*1,self.weights:1*4,hidden_neural == 4\n",
    "        self.output = activation_function(self.choice2,\n",
    "                                          np.dot(self.layer1, self.weights2) + self.bias2 * np.ones(self.y.shape[1]))\n",
    "\n",
    "    def backpropagation(self, current_x, current_y):\n",
    "        d_weights2 = np.dot(self.layer1.T, np.multiply(2 * (self.output - mat(current_y)),\n",
    "                                                       function_derivative(self.choice2,\n",
    "                                                                           self.output)))  # 这里的 *是点乘，适合输出为多维情况\n",
    "        d_weights1 = np.dot(mat(current_x).T, np.multiply(\n",
    "            np.dot(np.multiply(function_derivative(self.choice2, self.output), 2 * (self.output - mat(current_y))),\n",
    "                   self.weights2.T), function_derivative(self.choice, self.layer1)))\n",
    "        d_bias2 = np.dot(2 * (self.output - mat(current_y)), function_derivative(self.choice, self.output).T)\n",
    "        d_bias1 = np.dot(\n",
    "            np.dot(np.multiply(function_derivative(self.choice, self.output), 2 * (self.output - mat(current_y))),\n",
    "                   self.weights2.T), function_derivative(self.choice, self.layer1).T)\n",
    "\n",
    "        # update weights and bias\n",
    "        self.weights1 -= self.learning_rate * d_weights1\n",
    "        self.weights2 -= self.learning_rate * d_weights2\n",
    "        self.bias1 -= self.learning_rate * d_bias1\n",
    "        self.bias2 -= self.learning_rate * d_bias2\n",
    "\n",
    "    # def train(self):\n",
    "    #     #         batch = 30\n",
    "    #     #         i = random.randint(0,120)\n",
    "    #     for i in range(self.input.shape[0]):\n",
    "    #         self.feedforward(self.input[i])\n",
    "    #         self.backpropagation(self.input[i], self.y[i])\n",
    "    #         #         for i in range(self.input.shape[0]):\n",
    "    #         #             self.feedforward(self.input[i])\n",
    "    #         self.loss += np.sum(np.square(self.output - self.y[i])) / self.input.shape[0]\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        for i in range(self.input.shape[0]):\n",
    "            self.feedforward(self.input[i])\n",
    "            self.backpropagation(self.input[i], self.y[i])\n",
    "        for j in range(self.input.shape[0]):\n",
    "            self.feedforward(self.input[j])\n",
    "            self.loss += np.sum(np.square(self.output - self.y[j])) / self.input.shape[0]\n",
    "\n",
    "    def test(self, test_x, test_y):\n",
    "        prediction = np.zeros((test_y.shape[0], test_y.shape[1]))\n",
    "        for i in range(test_x.shape[0]):\n",
    "            self.feedforward(test_x[i])\n",
    "            prediction[i] = self.output[0]\n",
    "        print(prediction)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # x = np.linspace(-1,1,num = 300)[:,np.newaxis]\n",
    "    # noise = np.random.normal(0, 0.05, x.shape).astype(np.float32)\n",
    "    # y = np.square(x) - 0.5 + noise\n",
    "\n",
    "    #     x = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
    "    #     y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "    #     x_test = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1],[0, 1, 1],[[1, 1, 0]]])\n",
    "    #     y_test = np.array([[0],[1],[1],[0],[1],[0]])\n",
    "    # x = np.array([[0,0],[1,0],[1,1],[0,1]])\n",
    "    # y = np.array([[0],[0],[1],[0]])\n",
    "\n",
    "    NN = NeuralNetwork(data_x, data_y)\n",
    "    for j in range(1500):\n",
    "        NN.loss = 0\n",
    "        NN.train()\n",
    "\n",
    "        if j % 50 == 0:\n",
    "            print(NN.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.37534711e-01 3.37534711e-01 3.37534711e-01]\n",
      " [3.37534711e-01 3.37534711e-01 3.37534711e-01]\n",
      " [3.37534711e-01 3.37534711e-01 3.37534711e-01]\n",
      " [3.37534711e-01 3.37534711e-01 3.37534711e-01]\n",
      " [3.37534711e-01 3.37534711e-01 3.37534711e-01]\n",
      " [3.37534711e-01 3.37534711e-01 3.37534711e-01]\n",
      " [3.37534711e-01 3.37534711e-01 3.37534711e-01]\n",
      " [3.37534711e-01 3.37534711e-01 3.37534711e-01]\n",
      " [3.37534711e-01 3.37534711e-01 3.37534711e-01]\n",
      " [3.37534711e-01 3.37534711e-01 3.37534711e-01]\n",
      " [3.37534711e-01 3.37534711e-01 3.37534711e-01]\n",
      " [5.40836029e-07 9.56945771e-01 3.81545370e-02]\n",
      " [2.06345815e-07 6.88860237e-01 2.58818671e-01]\n",
      " [1.24808778e-10 9.63484494e-01 4.40104829e-02]\n",
      " [1.22575978e-07 9.99880293e-01 1.60035337e-04]\n",
      " [5.11474666e-03 9.20558062e-01 3.64223810e-02]\n",
      " [7.60326316e-08 9.71038636e-01 2.78352190e-02]\n",
      " [3.68772455e-08 9.99937634e-01 9.14787560e-05]\n",
      " [2.22412927e-08 9.98914344e-01 1.32277098e-03]\n",
      " [5.62743748e-10 9.99919730e-01 1.35308832e-04]\n",
      " [2.31911210e-03 9.52097631e-01 2.35526243e-02]\n",
      " [4.26009483e-08 9.99111004e-01 1.08057550e-03]\n",
      " [1.02783312e-16 8.28738267e-08 9.99999880e-01]\n",
      " [1.75957578e-17 1.06897478e-12 1.00000000e+00]\n",
      " [6.41217903e-17 7.21513043e-08 9.99999899e-01]\n",
      " [6.71618402e-12 5.13629881e-10 9.99999998e-01]\n",
      " [4.99463173e-18 1.02213933e-12 1.00000000e+00]\n",
      " [3.15409336e-18 3.23710222e-13 1.00000000e+00]\n",
      " [2.21887942e-16 9.56412577e-10 9.99999998e-01]\n",
      " [6.23435794e-13 1.03748528e-08 9.99999976e-01]\n",
      " [8.80261562e-15 1.58859595e-07 9.99999732e-01]\n",
      " [9.39850859e-16 1.35360991e-10 1.00000000e+00]\n",
      " [3.24536852e-12 4.64641046e-07 9.99999031e-01]]\n"
     ]
    }
   ],
   "source": [
    "NN.test(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.60346339, 0.55294892, 0.56598759, 0.00463989],\n",
       "       [0.29861183, 0.61777568, 0.96514733, 0.00568809],\n",
       "       [0.90294718, 0.57296699, 0.29898411, 0.82365922]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
